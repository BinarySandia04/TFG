{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca940fc4-50cb-4c46-b974-56ae84eb00d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import numpy as np\n",
    "import tednet.tednet.tnn.tensor_ring as tednet_tr\n",
    "import tednet.tednet.tnn.tensor_train as tednet_tt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3abc58e-1093-41e3-935c-681bdabde8a8",
   "metadata": {},
   "source": [
    "# Model setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e360cc-5d40-446b-b597-80a9d16ed8f7",
   "metadata": {},
   "source": [
    "## Tensor Layer definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40c935d1-04f2-438f-a541-6c861143d158",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TRLinearLayer(nn.Module):\n",
    "    def __init__(self, in_shape, out_shape, ranks, bias: bool = True):\n",
    "        super().__init__()\n",
    "        self.n_info = {}\n",
    "        self.layer = tednet_tr.TRLinear(in_shape, out_shape, ranks, bias=bias)\n",
    "        self.n_info[\"ori_params\"] = self.layer.tn_info[\"ori_params\"]\n",
    "        self.n_info[\"t_params\"] = self.layer.tn_info[\"t_params\"]\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "class TTLinearLayer(nn.Module):\n",
    "    def __init__(self, in_shape, out_shape, ranks, bias: bool = True):\n",
    "        super().__init__()\n",
    "        self.n_info = {}\n",
    "        self.layer = tednet_tt.TTLinear(in_shape, out_shape, ranks, bias=bias)\n",
    "        self.n_info[\"ori_params\"] = self.layer.tn_info[\"ori_params\"]\n",
    "        self.n_info[\"t_params\"] = self.layer.tn_info[\"t_params\"]\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26989e2-c55f-41a7-a1b1-addb6b60f62d",
   "metadata": {},
   "source": [
    "## Model definitions\n",
    "We test different tensor decompositions methods by training a fully connected network model over the MNIST dataset.\n",
    "The test model has layers [784, 320, 100, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b10f3b39-d795-4c26-8621-01a270b45cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LeNet-300-100 model\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(784, 320),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(320, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 10), # Returns logits\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "class LeNetTR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNetTR, self).__init__()\n",
    "        self.n_info = {}\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.l1 = TRLinearLayer([7,7,4,4], [5,8,8], [7,7,4,4,5,8,8], bias=True)\n",
    "        self.l2 = TRLinearLayer([5,8,8], [10, 10], [5,5,5,5,5], bias=True)\n",
    "        self.l3 = TRLinearLayer([10,10], [10], [5,5,5], bias=True)\n",
    "        self.classifier = nn.Sequential(\n",
    "            self.l1,\n",
    "            nn.ReLU(),\n",
    "            self.l2,\n",
    "            nn.ReLU(),\n",
    "            self.l3, # Returns logits\n",
    "        )\n",
    "        self.n_info[\"ori_params\"] = sum([x.n_info[\"ori_params\"] for x in [self.l1, self.l2, self.l3]])\n",
    "        self.n_info[\"t_params\"] = sum([x.n_info[\"t_params\"] for x in [self.l1, self.l2, self.l3]])\n",
    "        self.n_info[\"cr\"] = self.n_info[\"ori_params\"] / self.n_info[\"t_params\"]\n",
    "\n",
    "        print(\"LeNet TR ---\")\n",
    "        print(\"Original params: \" + str(self.n_info[\"ori_params\"]))\n",
    "        print(\"TN params: \" + str(self.n_info[\"t_params\"]))\n",
    "        print(\"Compression ratio: \" + str(self.n_info[\"cr\"]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "        \n",
    "class LeNetTT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNetTT, self).__init__()\n",
    "        self.n_info = {}\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.l1 = TTLinearLayer([7,7,4,4], [5,4,4,4], [4,4,4], bias=True)\n",
    "        self.l2 = TTLinearLayer([5,4,4,4], [5,5,2,2], [4,4,4], bias=True)\n",
    "        self.l3 = TTLinearLayer([5,5,2,2], [1,1,1,10], [4,4,4], bias=True)\n",
    "        self.classifier = nn.Sequential(\n",
    "            self.l1,\n",
    "            nn.ReLU(),\n",
    "            self.l2,\n",
    "            nn.ReLU(),\n",
    "            self.l3, # Returns logits\n",
    "        )\n",
    "        self.n_info[\"ori_params\"] = sum([x.n_info[\"ori_params\"] for x in [self.l1, self.l2, self.l3]])\n",
    "        self.n_info[\"t_params\"] = sum([x.n_info[\"t_params\"] for x in [self.l1, self.l2, self.l3]])\n",
    "        self.n_info[\"cr\"] = self.n_info[\"ori_params\"] / self.n_info[\"t_params\"]\n",
    "\n",
    "        print(\"LeNet TT ---\")\n",
    "        print(\"Original params: \" + str(self.n_info[\"ori_params\"]))\n",
    "        print(\"TN params: \" + str(self.n_info[\"t_params\"]))\n",
    "        print(\"Compression ratio: \" + str(self.n_info[\"cr\"]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc65f0c-c2f4-43a3-87d6-c1e3fabe7061",
   "metadata": {},
   "source": [
    "# Training functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11912b64-a0fd-4f58-9369-9f0d46f9f6e2",
   "metadata": {},
   "source": [
    "## Training helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baeda3e7-08ab-400c-8369-54c6a9be7163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_validation_set(model, validation_loader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for x_val, y_val in validation_loader:\n",
    "            x_val = x_val.to(device)\n",
    "            y_val = y_val.to(device)\n",
    "\n",
    "            outputs = model(x_val)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += y_val.size(0)\n",
    "            correct += (predicted == y_val).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def show_example_batch(train_data):\n",
    "    # Get the first batch\n",
    "    train_loader, valid_loader = train_data\n",
    "    \n",
    "    dataiter = iter(train_loader)\n",
    "    images, labels = next(dataiter)\n",
    "    \n",
    "    # Plot the images in the batch, along with the corresponding labels\n",
    "    fig = plt.figure(figsize=(25, 4))\n",
    "    plot_size=20\n",
    "    for idx in np.arange(plot_size):\n",
    "        ax = fig.add_subplot(2, int(plot_size/2), idx+1, xticks=[], yticks=[])\n",
    "        ax.imshow(np.squeeze(images[idx].numpy()), cmap='gray')\n",
    "        # print out the correct label for each image\n",
    "        # .item() gets the value contained in a Tensor\n",
    "        ax.set_title(str(labels[idx].item()))\n",
    "    plt.imshow(images[0].numpy().squeeze(), cmap='gray_r')\n",
    "def get_train_data():\n",
    "    transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                  transforms.Normalize((0.1307,), (0.3081,)),\n",
    "                                  ])\n",
    "    # Download and load the training data\n",
    "    trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "    validation_size = 0.10\n",
    "    num_train = len(trainset)\n",
    "    indices = list(range(num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    # Calculate the number of data points in the validation set\n",
    "    split = int(np.floor(validation_size * num_train))\n",
    "    print(split)\n",
    "    \n",
    "    # Train_idx => Imatges per entrenar\n",
    "    # Valid_idx => Imatges per verificar i comprovar el model\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    \n",
    "    # Create data samplers\n",
    "    train_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = torch.utils.data.sampler.SubsetRandomSampler(valid_idx)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=64, sampler=train_sampler)\n",
    "    valid_loader = torch.utils.data.DataLoader(trainset, batch_size=64, sampler=valid_sampler)\n",
    "\n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35ced89-f2f6-4338-8993-4f7ba4987481",
   "metadata": {},
   "source": [
    "## Train model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f612b704-3e69-4085-88ec-d8892c90f99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, device, train_data, learning_rate=1.2e-3, batch_size=60, epochs=10):\n",
    "    losses = []\n",
    "    accuracy_list = []\n",
    "    val_accuracy_list = []\n",
    "    grad_norms = []\n",
    "    print(\"Training model\")\n",
    "    print(model)\n",
    "\n",
    "    train_loader, valid_loader = train_data\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    for param in model.parameters():\n",
    "        print(param)\n",
    "    # Validation Calculation\n",
    "    val_check_iter = 3\n",
    "    iterations_per_epoch = len(train_loader)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "            # Move data to the device\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            output = model(x_batch)\n",
    "            loss = nn.CrossEntropyLoss()(output, y_batch)\n",
    "            loss.backward()\n",
    "    \n",
    "    \n",
    "            # Calculate and store gradient norm\n",
    "            total_grad_norm = torch.sqrt(sum(p.grad.norm()**2 for p in model.parameters() if p.grad is not None))\n",
    "            grad_norms.append(total_grad_norm.item())\n",
    "    \n",
    "            optimizer.step()\n",
    "    \n",
    "            # Store the loss\n",
    "            losses.append(loss.item())\n",
    "    \n",
    "            # Store the accuracy \n",
    "            _, argmax = torch.max(output, 1)\n",
    "            accuracy = (y_batch == argmax.squeeze()).float().mean()\n",
    "            accuracy_list.append(accuracy)\n",
    "    \n",
    "            if i % int(len(train_loader) / 50) == 0:\n",
    "                print(\".\", end='')\n",
    "    \n",
    "            if i % int(len(train_loader) / val_check_iter) == 0:\n",
    "                # Calculate validation accuracy at the end of each epoch\n",
    "                val_accuracy = evaluate_validation_set(model, valid_loader, device)\n",
    "                val_accuracy_list.append(val_accuracy)\n",
    "                \n",
    "                # Calculate average loss and accuracy over an epoch\n",
    "                avg_loss = torch.mean(torch.tensor(losses[-len(train_loader):]))\n",
    "                avg_accuracy = torch.mean(torch.tensor(accuracy_list[-len(train_loader):]))\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {avg_loss.item():.4f}, Accuracy: {avg_accuracy.item():.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
    "    infos = {\n",
    "        \"losses\": losses,\n",
    "        \"accuracy_list\": accuracy_list,\n",
    "        \"grad_norms\": grad_norms,\n",
    "        \"val_accuracy_list\": val_accuracy_list,\n",
    "        \"iterations_per_epoch\": iterations_per_epoch,\n",
    "        \"model_name\": model.__class__.__name__\n",
    "    }\n",
    "    return infos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750fcab5-cf45-4c20-8593-b7e9abfcd4f7",
   "metadata": {},
   "source": [
    "## Show training results function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7043f520-0bff-463f-b0c1-3a0fa929151d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_training_infos(training_infos, epochs):\n",
    "    \n",
    "    average_window = 200\n",
    "    infos = []\n",
    "    for training_info in training_infos:\n",
    "        losses = torch.tensor(training_info[\"losses\"]).cpu().numpy()\n",
    "        accuracy_list = torch.tensor(training_info[\"accuracy_list\"]).cpu().numpy()\n",
    "        grad_norms = torch.tensor(training_info[\"grad_norms\"]).cpu().numpy()\n",
    "        val_accuracy_list = training_info[\"val_accuracy_list\"]\n",
    "        iterations_per_epoch = training_info[\"iterations_per_epoch\"]\n",
    "\n",
    "        average_losses = [np.mean(losses[i-average_window:i]) for i in range(0, len(losses), average_window)]\n",
    "        avg_accuracy_list = [np.mean(accuracy_list[i-average_window:i]) for i in range(0, len(accuracy_list), average_window)]\n",
    "        avg_grad_norms = [np.mean(grad_norms[i-average_window:i]) for i in range(0, len(grad_norms), average_window)]\n",
    "\n",
    "        iterations = np.arange(len(average_losses)) * average_window\n",
    "        x_iterations = np.arange(0, iterations_per_epoch * epochs,(iterations_per_epoch * epochs) / len(val_accuracy_list))\n",
    "        infos.append({\n",
    "            \"name\": training_info[\"model_name\"],\n",
    "            \"iterations\": iterations,\n",
    "            \"average_losses\": average_losses,\n",
    "            \"avg_grad_norms\": avg_grad_norms,\n",
    "            \"avg_accuracy_list\": avg_accuracy_list,\n",
    "            \"val_accuracy_list\": val_accuracy_list,\n",
    "            \"x_iterations\": x_iterations\n",
    "        })\n",
    "    \n",
    "    # Plotting the loss curve (average, with max and min as error bands)\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for info in infos:\n",
    "        plt.plot(info[\"iterations\"], info[\"average_losses\"], label=info[\"name\"])\n",
    "    \n",
    "    plt.ylim(0, .5)\n",
    "    \n",
    "    plt.title('Training Loss Curve Average')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plotting the gradient norm curve\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for info in infos:\n",
    "        plt.plot(info[\"iterations\"], info[\"avg_grad_norms\"], label=info[\"name\"])\n",
    "    plt.title('Gradient Norm Curve Average')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Gradient Norm')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plotting the accuracy curve (average, with max and min as error bars)\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for info in infos:\n",
    "        plt.plot(info[\"iterations\"], info[\"avg_accuracy_list\"], label=info[\"name\"])\n",
    "    plt.title('Training Accuracy Curve Average')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Zoom to 0.9 to 1.0 range\n",
    "    plt.ylim(0.9, 1.0)\n",
    "    \n",
    "    # Plotting the validation accuracy curve\n",
    "    x_iterations = np.arange(0, iterations_per_epoch * epochs,(iterations_per_epoch * epochs) / len(val_accuracy_list))\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for info in infos:\n",
    "        plt.plot(info[\"x_iterations\"], info[\"val_accuracy_list\"], label=info[\"name\"])\n",
    "    plt.title('Validation Accuracy Curve Average')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Zoom to 0.94 to 1.0 range\n",
    "    plt.ylim(0.94, 1.0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4144a0d-3761-4162-9c2e-17e37491c3e3",
   "metadata": {},
   "source": [
    "## Model test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1a81ff2-c7a1-4b87-a3fb-362e79806cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "def test_model(model):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    print(model)\n",
    "    \n",
    "    # Download and load the test data\n",
    "    testset = datasets.MNIST('MNIST_data/', download=True, train=False, transform=transform)\n",
    "    test_loader = DataLoader(testset, batch_size=64, shuffle=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in test_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "    \n",
    "            output = model(x_batch)\n",
    "            test_loss += nn.CrossEntropyLoss()(output, y_batch).item()\n",
    "    \n",
    "            _, argmax = torch.max(output, 1)\n",
    "            correct += (y_batch == argmax.squeeze()).float().sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = correct / len(test_loader.dataset)\n",
    "    \n",
    "    print(f'Test loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9505057-0ea4-4929-a781-4c51c973d4aa",
   "metadata": {},
   "source": [
    "# Actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16a917c5-f686-4961-9b3e-45ee043d097a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet TR ---\n",
      "Original params: 283880\n",
      "TN params: 3618\n",
      "Compression ratio: 78.46323935876174\n",
      "compression_ration is:  276.2995594713656\n",
      "compression_ration is:  55.172413793103445\n",
      "compression_ration is:  4.716981132075472\n",
      "LeNet TT ---\n",
      "Original params: 283880\n",
      "TN params: 1700\n",
      "Compression ratio: 166.98823529411766\n",
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    LeNetTR(), LeNetTT(), LeNet()\n",
    "]\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "for x in models:\n",
    "    x.to(device)\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d31d6d9-be51-45cc-85b1-01721ee79c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n",
      "Training model\n",
      "LeNet(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=320, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=320, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Parameter containing:\n",
      "tensor([[-0.0328, -0.0008,  0.0249,  ..., -0.0200,  0.0080, -0.0281],\n",
      "        [ 0.0185,  0.0167,  0.0329,  ...,  0.0293, -0.0023, -0.0325],\n",
      "        [ 0.0039, -0.0181, -0.0266,  ..., -0.0067, -0.0284,  0.0294],\n",
      "        ...,\n",
      "        [-0.0356,  0.0238,  0.0038,  ...,  0.0084,  0.0087, -0.0033],\n",
      "        [-0.0181,  0.0310,  0.0168,  ..., -0.0184, -0.0035,  0.0098],\n",
      "        [-0.0248, -0.0201,  0.0252,  ...,  0.0065, -0.0147,  0.0234]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-1.4427e-02,  3.3118e-02,  5.9915e-04, -2.3209e-02,  3.2347e-02,\n",
      "        -3.4246e-02,  2.8080e-02, -1.9139e-02,  2.8579e-02,  1.2097e-03,\n",
      "         1.8066e-02, -1.2677e-02, -1.0396e-02,  1.5444e-02, -2.6003e-02,\n",
      "        -2.8073e-03, -7.9208e-03, -3.2890e-02,  2.4678e-02, -5.2663e-03,\n",
      "        -9.0354e-04,  2.3596e-02,  3.2652e-02,  2.2406e-02,  1.2437e-02,\n",
      "        -2.2980e-02, -1.3478e-02, -2.8209e-02,  7.3964e-03, -7.8059e-03,\n",
      "         3.1371e-02,  3.2883e-02, -9.5805e-03, -2.8017e-02,  2.4133e-02,\n",
      "         9.4679e-03,  3.1321e-02,  3.0299e-02,  3.3649e-02,  2.4906e-02,\n",
      "        -1.4190e-02, -9.7272e-03,  1.7236e-02,  1.6947e-02,  3.4767e-02,\n",
      "        -2.4051e-02,  2.1019e-02,  2.4203e-02, -1.7918e-02, -2.4466e-02,\n",
      "         1.9255e-02, -3.1249e-02,  1.4636e-02, -5.4287e-04, -3.5285e-02,\n",
      "         3.2871e-03,  1.9946e-03, -9.7763e-03, -6.3330e-03, -1.4171e-02,\n",
      "        -2.0817e-02, -1.9983e-02,  3.5624e-02, -3.1238e-02,  1.0984e-02,\n",
      "        -9.0662e-03, -2.7153e-02, -8.6946e-03, -1.5851e-02,  2.8194e-02,\n",
      "         5.1459e-03,  5.1067e-03,  2.7864e-02, -2.3358e-02,  1.6886e-02,\n",
      "        -4.7738e-04, -1.8160e-02, -6.3979e-03,  1.6508e-02,  4.3385e-03,\n",
      "         1.4662e-02,  2.3077e-02, -3.8381e-03,  1.5473e-02,  1.4595e-02,\n",
      "        -7.4529e-03,  2.1467e-02, -2.4965e-02, -2.0229e-02,  9.6966e-03,\n",
      "        -2.1846e-02,  3.1043e-03, -1.4438e-02,  3.5612e-02, -7.6803e-03,\n",
      "        -1.2385e-02, -2.6681e-03, -2.9989e-02, -2.9619e-02, -2.2168e-03,\n",
      "        -1.8155e-02, -4.8473e-03,  5.9137e-03,  4.1433e-03, -1.4282e-02,\n",
      "         2.0254e-02,  4.5363e-03,  2.8977e-02,  3.1686e-02, -1.7766e-02,\n",
      "        -3.5351e-02, -2.4829e-02, -2.7253e-02, -7.9579e-03,  2.1867e-02,\n",
      "         2.7516e-02,  1.2954e-02,  1.8028e-02,  2.3243e-02,  9.5673e-04,\n",
      "        -2.9092e-02,  1.7305e-02,  1.7102e-02,  3.1261e-02,  2.6705e-02,\n",
      "        -1.5747e-03,  4.7403e-03, -3.2628e-02, -9.2097e-03, -6.7302e-03,\n",
      "         3.0378e-02,  1.0923e-02,  2.3876e-02,  2.5726e-02, -3.0449e-02,\n",
      "        -2.8763e-02,  2.1532e-02, -1.3713e-02, -3.0994e-02, -3.1293e-02,\n",
      "         3.1272e-02,  1.0370e-02, -1.3130e-03,  4.6651e-03, -5.0906e-03,\n",
      "         2.7678e-02, -3.3285e-02, -3.0702e-02, -2.5109e-02, -1.1960e-02,\n",
      "         3.3488e-02,  5.6718e-03, -2.6427e-02, -3.8907e-03,  2.5960e-02,\n",
      "        -9.1052e-03, -2.2351e-03, -1.9501e-02,  1.5582e-02, -2.4359e-02,\n",
      "         2.8589e-02, -3.2204e-03, -3.2462e-02, -3.3757e-02,  3.4321e-02,\n",
      "        -2.8171e-02,  1.7263e-02, -2.4568e-03,  9.8714e-03,  2.4856e-02,\n",
      "         2.4163e-02,  6.7565e-03,  1.3792e-02,  1.1455e-02, -4.1067e-03,\n",
      "        -6.1818e-03, -2.9577e-02,  1.1117e-02, -2.3636e-02,  2.7766e-02,\n",
      "        -7.5171e-03, -3.0606e-03, -6.9753e-03,  3.1481e-02,  1.5576e-02,\n",
      "        -3.5553e-02,  1.1841e-02, -1.2565e-02,  1.5504e-02,  3.4681e-02,\n",
      "        -8.2574e-03, -7.5135e-03,  3.2428e-02,  2.7442e-02,  1.1825e-02,\n",
      "        -1.8837e-02, -2.2282e-02,  2.6520e-02,  1.6594e-02, -3.4438e-02,\n",
      "        -4.0518e-03, -3.8325e-03, -1.8682e-02, -1.5809e-02, -1.2352e-02,\n",
      "        -3.2283e-02, -2.4951e-02,  2.3167e-02,  3.4533e-03,  1.2760e-02,\n",
      "         1.3788e-02,  2.4410e-02,  2.0901e-02,  5.6765e-05, -6.5278e-03,\n",
      "        -3.1762e-02,  2.2900e-04,  2.0127e-02,  2.3381e-02, -1.9976e-02,\n",
      "         8.1496e-03, -1.6167e-02,  3.5482e-02, -1.5168e-02, -3.0917e-02,\n",
      "        -5.2648e-03,  1.8270e-02, -3.2171e-02, -3.1595e-02,  5.8708e-03,\n",
      "         3.2898e-02,  5.6694e-03,  8.0838e-03, -2.1387e-02, -1.3886e-02,\n",
      "        -2.2161e-02, -1.9188e-02,  1.2768e-02, -2.9463e-02, -2.7888e-02,\n",
      "        -2.6488e-02,  2.3218e-02,  3.0911e-02,  2.0918e-02, -2.3714e-02,\n",
      "         3.2337e-02, -1.8024e-02, -1.1013e-02, -1.3390e-02,  1.1733e-03,\n",
      "        -2.1748e-02, -1.7896e-02,  1.3360e-02,  4.5225e-03, -2.3006e-02,\n",
      "         1.8112e-02, -3.0579e-02, -9.1041e-03, -2.2018e-02,  5.6208e-03,\n",
      "        -1.6258e-02, -1.6208e-02,  2.5259e-02, -1.6182e-02,  2.8630e-02,\n",
      "         2.2164e-02, -3.1736e-02, -1.4593e-02,  1.1802e-02,  3.2909e-03,\n",
      "         2.7354e-02,  6.3254e-03,  2.8544e-02, -2.2831e-02, -2.9015e-02,\n",
      "        -6.8891e-03,  2.8182e-02, -3.5226e-02,  3.2596e-02,  2.4215e-02,\n",
      "        -1.0627e-02,  2.5613e-02, -2.4333e-02,  2.3598e-02,  1.5474e-02,\n",
      "         2.0685e-02, -2.7902e-02,  1.9915e-02,  1.7740e-02, -1.3376e-02,\n",
      "        -2.0435e-03,  6.5778e-03, -3.0200e-02, -2.2010e-02,  2.7400e-02,\n",
      "        -2.3064e-02,  1.2693e-02, -1.6533e-02, -3.5746e-03,  9.9521e-03,\n",
      "         3.1300e-02,  2.9433e-02, -2.4078e-03, -2.2779e-02, -3.4496e-02,\n",
      "        -2.4517e-02, -2.0581e-02, -7.9041e-03, -2.2607e-02, -3.0232e-02,\n",
      "         2.3017e-02,  8.6778e-03,  8.0184e-03,  1.2363e-02, -5.0960e-03,\n",
      "        -1.8477e-02,  1.6248e-02, -1.8416e-02, -1.2090e-02,  2.9590e-02],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0358,  0.0017, -0.0270,  ..., -0.0209,  0.0386,  0.0172],\n",
      "        [ 0.0358, -0.0486,  0.0003,  ...,  0.0220,  0.0010,  0.0433],\n",
      "        [-0.0092, -0.0272,  0.0297,  ...,  0.0066, -0.0518, -0.0503],\n",
      "        ...,\n",
      "        [ 0.0360, -0.0199, -0.0074,  ..., -0.0470,  0.0055, -0.0304],\n",
      "        [ 0.0361,  0.0354,  0.0076,  ...,  0.0300, -0.0185,  0.0285],\n",
      "        [ 0.0111, -0.0210, -0.0230,  ..., -0.0413,  0.0446,  0.0026]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0492,  0.0226, -0.0106, -0.0514, -0.0228, -0.0548, -0.0005,  0.0295,\n",
      "         0.0310,  0.0421,  0.0272,  0.0103,  0.0328, -0.0224, -0.0467,  0.0554,\n",
      "         0.0337,  0.0375, -0.0233,  0.0194,  0.0340, -0.0451,  0.0550, -0.0113,\n",
      "        -0.0364,  0.0208,  0.0411,  0.0030,  0.0257,  0.0420, -0.0389, -0.0037,\n",
      "        -0.0370, -0.0063, -0.0328,  0.0052, -0.0533, -0.0373, -0.0555, -0.0514,\n",
      "         0.0054,  0.0396, -0.0123, -0.0474, -0.0225, -0.0260,  0.0013, -0.0128,\n",
      "        -0.0439,  0.0296, -0.0083,  0.0273,  0.0515,  0.0361, -0.0424,  0.0441,\n",
      "        -0.0012, -0.0226,  0.0088,  0.0226, -0.0126, -0.0442,  0.0086, -0.0435,\n",
      "        -0.0251, -0.0395,  0.0051,  0.0285, -0.0428,  0.0272, -0.0389, -0.0137,\n",
      "        -0.0051, -0.0297,  0.0455,  0.0063, -0.0114,  0.0037,  0.0518,  0.0108,\n",
      "         0.0345,  0.0391, -0.0275, -0.0430, -0.0030, -0.0438,  0.0263, -0.0203,\n",
      "        -0.0296, -0.0437, -0.0120, -0.0379,  0.0522,  0.0303,  0.0241,  0.0423,\n",
      "        -0.0053, -0.0171,  0.0514,  0.0438], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0832, -0.0364, -0.0505, -0.0444, -0.0768,  0.0542,  0.0362, -0.0196,\n",
      "         -0.0358, -0.0868,  0.0649, -0.0558, -0.0596,  0.0468, -0.0211, -0.0599,\n",
      "          0.0078,  0.0789, -0.0653,  0.0351, -0.0390, -0.0221,  0.0022,  0.0266,\n",
      "          0.0256, -0.0919,  0.0788, -0.0425,  0.0312,  0.0689, -0.0054, -0.0987,\n",
      "         -0.0623, -0.0608,  0.0197,  0.0103,  0.0923, -0.0006, -0.0418, -0.0358,\n",
      "          0.0603, -0.0165, -0.0711,  0.0223,  0.0406,  0.0471, -0.0844,  0.0326,\n",
      "         -0.0221,  0.0889, -0.0772, -0.0228,  0.0265, -0.0670, -0.0858,  0.0008,\n",
      "         -0.0681,  0.0597, -0.0375, -0.0354, -0.0297,  0.0323, -0.0697,  0.0834,\n",
      "          0.0420, -0.0977, -0.0338, -0.0415,  0.0812,  0.0998, -0.0665,  0.0187,\n",
      "          0.0861, -0.0078,  0.0482, -0.0108, -0.0062, -0.0590, -0.0519,  0.0719,\n",
      "         -0.0880,  0.0309,  0.0083,  0.0137,  0.0054, -0.0894,  0.0195, -0.0226,\n",
      "         -0.0672,  0.0775, -0.0265,  0.0578, -0.0278,  0.0416,  0.0425,  0.0745,\n",
      "         -0.0786,  0.0717,  0.0270,  0.0506],\n",
      "        [ 0.0560,  0.0887, -0.0471, -0.0117, -0.0152, -0.0841, -0.0043,  0.0691,\n",
      "         -0.0483, -0.0064, -0.0030, -0.0423, -0.0978,  0.0402, -0.0248,  0.0301,\n",
      "          0.0230,  0.0661, -0.0864,  0.0262,  0.0414,  0.0422, -0.0188, -0.0697,\n",
      "         -0.0911,  0.0534,  0.0663,  0.0347, -0.0132, -0.0244, -0.0512,  0.0122,\n",
      "         -0.0028,  0.0795,  0.0213,  0.0549,  0.0605, -0.0162,  0.0903, -0.0935,\n",
      "          0.0095, -0.0815,  0.0331, -0.0570,  0.0246, -0.0649, -0.0098, -0.0166,\n",
      "          0.0565,  0.0330,  0.0251, -0.0032, -0.0043, -0.0294, -0.0231, -0.0432,\n",
      "         -0.0656, -0.0975, -0.0279,  0.0254,  0.0979, -0.0383,  0.0123,  0.0055,\n",
      "          0.0789,  0.0400, -0.0311,  0.0804,  0.0136,  0.0162,  0.0858, -0.0911,\n",
      "          0.0805, -0.0356,  0.0416,  0.0793, -0.0720,  0.0721,  0.0289, -0.0682,\n",
      "         -0.0464,  0.0441,  0.0516,  0.0677, -0.0109, -0.0277,  0.0195, -0.0158,\n",
      "         -0.0828,  0.0321, -0.0269, -0.0634, -0.0972,  0.0369, -0.0296,  0.0550,\n",
      "          0.0541, -0.0738, -0.0016, -0.0616],\n",
      "        [-0.0956,  0.0338, -0.0252,  0.0027,  0.0589,  0.0290, -0.0033, -0.0817,\n",
      "          0.0977, -0.0885,  0.0687, -0.0351,  0.0251, -0.0147, -0.0132,  0.0965,\n",
      "          0.0043,  0.0511, -0.0769, -0.0268,  0.0016,  0.0231,  0.0224,  0.0039,\n",
      "         -0.0320,  0.0789, -0.0061, -0.0138, -0.0065,  0.0938, -0.0641, -0.0122,\n",
      "         -0.0795,  0.0080, -0.0789,  0.0815,  0.0037,  0.0042, -0.0451,  0.0859,\n",
      "         -0.0295,  0.0678,  0.0522,  0.0897, -0.0139, -0.0923, -0.0572,  0.0728,\n",
      "          0.0337,  0.0173, -0.0282,  0.0224, -0.0760, -0.0292,  0.0879,  0.0979,\n",
      "         -0.0865,  0.0614,  0.0916,  0.0296,  0.0013,  0.0369, -0.0870, -0.0044,\n",
      "         -0.0368, -0.0802,  0.0588,  0.0220, -0.0673,  0.0796, -0.0420, -0.0775,\n",
      "         -0.0838, -0.0811, -0.0092, -0.0270, -0.0495,  0.0125,  0.0035, -0.0696,\n",
      "         -0.0781,  0.0735, -0.0216,  0.0562,  0.0166, -0.0479,  0.0086, -0.0996,\n",
      "          0.0234,  0.0220,  0.0405,  0.0967,  0.0139, -0.0195,  0.0774,  0.0086,\n",
      "          0.0815,  0.0003,  0.0985,  0.0271],\n",
      "        [ 0.0576, -0.0811, -0.0973, -0.0887, -0.0192, -0.0256,  0.0078,  0.0880,\n",
      "         -0.0886, -0.0559, -0.0929,  0.0174, -0.0098,  0.0117, -0.0327,  0.0762,\n",
      "         -0.0995, -0.0199,  0.0608,  0.0932,  0.0074, -0.0528, -0.0607,  0.0929,\n",
      "         -0.0108,  0.0943,  0.0271, -0.0514, -0.0164,  0.0030, -0.0305, -0.0687,\n",
      "         -0.0637,  0.0162, -0.0799, -0.0758, -0.0249, -0.0160,  0.0625, -0.0271,\n",
      "         -0.0308, -0.0112,  0.0319,  0.0466,  0.0850,  0.0883,  0.0703, -0.0170,\n",
      "         -0.0260,  0.0965, -0.0140,  0.0234,  0.0044, -0.0107,  0.0709, -0.0785,\n",
      "          0.0112, -0.0745,  0.0376, -0.0287, -0.0833, -0.0081,  0.0020, -0.0368,\n",
      "          0.0835,  0.0427, -0.0994, -0.0896,  0.0302,  0.0391,  0.0827, -0.0166,\n",
      "         -0.0146, -0.0837,  0.0562,  0.0608,  0.0431, -0.0501, -0.0018, -0.0800,\n",
      "          0.0500,  0.0501, -0.0630, -0.0178, -0.0099, -0.0115,  0.0302,  0.0222,\n",
      "         -0.0044,  0.0645, -0.0493, -0.0956,  0.0089,  0.0604,  0.0504, -0.0915,\n",
      "         -0.0331, -0.0321,  0.0651,  0.0514],\n",
      "        [-0.0391, -0.0059, -0.0888, -0.0339, -0.0142, -0.0146,  0.0519, -0.0778,\n",
      "         -0.0018, -0.0353, -0.0130, -0.0360,  0.0821, -0.0047, -0.0577, -0.0679,\n",
      "         -0.0534, -0.0549,  0.0448,  0.0892,  0.0825,  0.0374, -0.0049,  0.0038,\n",
      "          0.0027,  0.0542,  0.0179, -0.0072, -0.0897, -0.0199, -0.0551, -0.0084,\n",
      "          0.0946,  0.0496,  0.0778,  0.0699,  0.0042,  0.0941,  0.0269,  0.0829,\n",
      "          0.0296,  0.0756,  0.0417,  0.0134, -0.0394,  0.0778,  0.0623, -0.0469,\n",
      "          0.0583, -0.0005, -0.0785,  0.0095,  0.0105, -0.0654, -0.0337, -0.0303,\n",
      "          0.0111,  0.0086,  0.0464,  0.0836,  0.0304,  0.0273,  0.0350, -0.0521,\n",
      "          0.0357, -0.0600,  0.0404,  0.0780, -0.0775, -0.0646,  0.0918, -0.0672,\n",
      "         -0.0451,  0.0204, -0.0011,  0.0873,  0.0094,  0.0092, -0.0711, -0.0808,\n",
      "         -0.0464,  0.0109, -0.0340,  0.0624,  0.0494,  0.0946,  0.0528, -0.0119,\n",
      "         -0.0330, -0.0953, -0.0364, -0.0309, -0.0377, -0.0794, -0.0417, -0.0805,\n",
      "         -0.0809, -0.0318, -0.0888,  0.0557],\n",
      "        [-0.0054, -0.0992,  0.0190, -0.0590,  0.0776, -0.0751, -0.0715, -0.0744,\n",
      "          0.0837, -0.0113, -0.0914, -0.0746,  0.0812,  0.0014, -0.0614, -0.0115,\n",
      "         -0.0303,  0.0719,  0.0628, -0.0586, -0.0190,  0.0251, -0.0128, -0.0384,\n",
      "         -0.0624,  0.0192,  0.0656,  0.0722, -0.0586, -0.0205,  0.0247,  0.0962,\n",
      "          0.0817,  0.0562,  0.0456, -0.0567,  0.0178, -0.0318, -0.0667, -0.0689,\n",
      "          0.0140, -0.0811, -0.0886, -0.0151, -0.0605, -0.0428, -0.0531, -0.0220,\n",
      "          0.0701,  0.0847,  0.0299,  0.0660, -0.0362,  0.0903,  0.0690, -0.0935,\n",
      "         -0.0160, -0.0706, -0.0709, -0.0235, -0.0771, -0.0250, -0.0755,  0.0321,\n",
      "         -0.0557, -0.0528,  0.0967, -0.0117, -0.0606, -0.0368,  0.0041, -0.0251,\n",
      "         -0.0057, -0.0896, -0.0255,  0.0401,  0.0292,  0.0207,  0.0085,  0.0738,\n",
      "          0.0204,  0.0781,  0.0629,  0.0350, -0.0266,  0.0258, -0.0449, -0.0029,\n",
      "         -0.0864, -0.0724, -0.0513,  0.0046,  0.0035,  0.0181, -0.0947, -0.0820,\n",
      "          0.0713, -0.0063,  0.0190, -0.0093],\n",
      "        [ 0.0942, -0.0643,  0.0436,  0.0168,  0.0325,  0.0670, -0.0190, -0.0765,\n",
      "         -0.0018, -0.0631, -0.0760,  0.0502,  0.0549,  0.0982, -0.0882,  0.0344,\n",
      "          0.0947,  0.0865,  0.0625, -0.0483,  0.0844,  0.0371, -0.0266, -0.0815,\n",
      "         -0.0086,  0.0034,  0.0465, -0.0942,  0.0013, -0.0719,  0.0054, -0.0756,\n",
      "         -0.0595, -0.0422, -0.0905,  0.0163,  0.0063, -0.0833, -0.0983, -0.0327,\n",
      "         -0.0699, -0.0035, -0.0572, -0.0650, -0.0572,  0.0890, -0.0034, -0.0642,\n",
      "          0.0830, -0.0185,  0.0239,  0.0089, -0.0237, -0.0416, -0.0794,  0.0046,\n",
      "          0.0493,  0.0505,  0.0135, -0.0897, -0.0483, -0.0242,  0.0995,  0.0517,\n",
      "         -0.0489,  0.0642,  0.0370, -0.0878, -0.0319, -0.0959,  0.0784,  0.0773,\n",
      "         -0.0646,  0.0495, -0.0034,  0.0014,  0.0435, -0.0129,  0.0469, -0.0618,\n",
      "         -0.0995,  0.0526, -0.0276, -0.0618,  0.0747, -0.0764,  0.0187,  0.0969,\n",
      "          0.0860,  0.0298,  0.0078, -0.0859,  0.0981,  0.0840, -0.0071, -0.0194,\n",
      "         -0.0473,  0.0665,  0.0635,  0.0915],\n",
      "        [ 0.0934, -0.0907,  0.0484,  0.0250,  0.0246, -0.0616,  0.0435,  0.0296,\n",
      "          0.0606, -0.0720,  0.0711,  0.0691, -0.0197, -0.0491, -0.0738, -0.0303,\n",
      "         -0.0399,  0.0131, -0.0930, -0.0767,  0.0766, -0.0670, -0.0365, -0.0966,\n",
      "          0.0786, -0.0780,  0.0941,  0.0877, -0.0606,  0.0331, -0.0952, -0.0068,\n",
      "         -0.0106,  0.0892, -0.0898, -0.0176, -0.0232,  0.0310, -0.0302,  0.0267,\n",
      "          0.0765, -0.0782, -0.0032, -0.0376,  0.0850, -0.0184,  0.0977,  0.0453,\n",
      "         -0.0402,  0.0404,  0.0228, -0.0103, -0.0912, -0.0980,  0.0908, -0.0228,\n",
      "         -0.0111, -0.0083, -0.0474,  0.0677, -0.0419, -0.0352, -0.0475, -0.0016,\n",
      "         -0.0242,  0.0363,  0.0653,  0.0728, -0.0429,  0.0605,  0.0891,  0.0447,\n",
      "         -0.0927,  0.0393,  0.0411,  0.0503, -0.0100,  0.0394,  0.0427, -0.0541,\n",
      "         -0.0209,  0.0531,  0.0623,  0.0912, -0.0410, -0.0956, -0.0456,  0.0948,\n",
      "         -0.0202,  0.0219, -0.0479,  0.0724, -0.0160, -0.0229,  0.0736,  0.0642,\n",
      "         -0.0007,  0.0662, -0.0068,  0.0576],\n",
      "        [ 0.0047,  0.0721, -0.0523, -0.0789,  0.0916, -0.0733,  0.0666,  0.0311,\n",
      "          0.0964, -0.0496,  0.0517,  0.0358, -0.0470,  0.0578,  0.0452, -0.0308,\n",
      "         -0.0128,  0.0306,  0.0852, -0.0433, -0.0696,  0.0299,  0.0156, -0.0618,\n",
      "         -0.0320,  0.0027,  0.0254,  0.0298,  0.0919, -0.0351,  0.0574, -0.0692,\n",
      "          0.0196, -0.0221, -0.0538, -0.0984,  0.0385,  0.0406,  0.0091,  0.0796,\n",
      "         -0.0594,  0.0506,  0.0219, -0.0790,  0.0737, -0.0236,  0.0158, -0.0431,\n",
      "         -0.0541,  0.0821,  0.0807,  0.0725,  0.0631, -0.0448, -0.0087, -0.0917,\n",
      "         -0.0588, -0.0770, -0.0092,  0.0306,  0.0083,  0.0635, -0.0066, -0.0259,\n",
      "          0.0082,  0.0336, -0.0223, -0.0887,  0.0263, -0.0676, -0.0230,  0.0119,\n",
      "         -0.0809,  0.0823,  0.0734, -0.0956, -0.0071, -0.0011, -0.0255, -0.0632,\n",
      "         -0.0133, -0.0044,  0.0265, -0.0711,  0.0223, -0.0994,  0.0086,  0.0625,\n",
      "          0.0259,  0.0730, -0.0972, -0.0084,  0.0774, -0.0424,  0.0352,  0.0379,\n",
      "          0.0951,  0.0676,  0.0510, -0.0913],\n",
      "        [-0.0577, -0.0237, -0.0579, -0.0746, -0.0150, -0.0644, -0.0331, -0.0893,\n",
      "          0.0322,  0.0301, -0.0543,  0.0683, -0.0985,  0.0021, -0.0436, -0.0510,\n",
      "          0.0024,  0.0910, -0.0604, -0.0303, -0.0256, -0.0249, -0.0910,  0.0124,\n",
      "          0.0360, -0.0204, -0.0880,  0.0791,  0.0271, -0.0677, -0.0920,  0.0496,\n",
      "         -0.0702, -0.0749, -0.0220, -0.0254, -0.0799,  0.0859,  0.0659,  0.0751,\n",
      "          0.0650,  0.0504,  0.0253,  0.0418, -0.0523, -0.0300, -0.0299, -0.0502,\n",
      "         -0.0302, -0.0155, -0.0403,  0.0442,  0.0296,  0.0236, -0.0906,  0.0597,\n",
      "         -0.0773,  0.0099, -0.0758, -0.0716,  0.0760, -0.0272, -0.0518, -0.0978,\n",
      "         -0.0104, -0.0792, -0.0811,  0.0221,  0.0811, -0.0869,  0.0671,  0.0719,\n",
      "         -0.0464, -0.0007,  0.0793, -0.0846,  0.0559,  0.0403, -0.0808, -0.0985,\n",
      "         -0.0639, -0.0006,  0.0988, -0.0842,  0.0154, -0.0374, -0.0443, -0.0826,\n",
      "          0.0611, -0.0655,  0.0415, -0.0461, -0.0401, -0.0842,  0.0649,  0.0376,\n",
      "          0.0926, -0.0305, -0.0346, -0.0115]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0845,  0.0783, -0.0494,  0.0976, -0.0302,  0.0187,  0.0072, -0.0819,\n",
      "         0.0324, -0.0118], device='cuda:0', requires_grad=True)\n",
      "....................................................Epoch 1/20, Loss: 0.2302, Accuracy: 0.9306, Val Accuracy: 0.9643\n",
      ".................."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m training_infos = []\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     training_infos.append(\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m      6\u001b[39m show_training_infos(training_infos, epochs)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, device, train_data, learning_rate, batch_size, epochs)\u001b[39m\n\u001b[32m     16\u001b[39m iterations_per_epoch = \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Move data to the device\u001b[39;49;00m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/torch/utils/data/dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/torchvision/datasets/mnist.py:146\u001b[39m, in \u001b[36mMNIST.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    143\u001b[39m img = Image.fromarray(img.numpy(), mode=\u001b[33m\"\u001b[39m\u001b[33mL\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     img = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.target_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    149\u001b[39m     target = \u001b[38;5;28mself\u001b[39m.target_transform(target)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/torchvision/transforms/transforms.py:95\u001b[39m, in \u001b[36mCompose.__call__\u001b[39m\u001b[34m(self, img)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         img = \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/torchvision/transforms/transforms.py:277\u001b[39m, in \u001b[36mNormalize.forward\u001b[39m\u001b[34m(self, tensor)\u001b[39m\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: Tensor) -> Tensor:\n\u001b[32m    270\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    271\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    272\u001b[39m \u001b[33;03m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    275\u001b[39m \u001b[33;03m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[32m    276\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/torchvision/transforms/functional.py:350\u001b[39m, in \u001b[36mnormalize\u001b[39m\u001b[34m(tensor, mean, std, inplace)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch.Tensor):\n\u001b[32m    348\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mimg should be Tensor Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m350\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_t\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/torchvision/transforms/_functional_tensor.py:921\u001b[39m, in \u001b[36mnormalize\u001b[39m\u001b[34m(tensor, mean, std, inplace)\u001b[39m\n\u001b[32m    919\u001b[39m dtype = tensor.dtype\n\u001b[32m    920\u001b[39m mean = torch.as_tensor(mean, dtype=dtype, device=tensor.device)\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m std = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (std == \u001b[32m0\u001b[39m).any():\n\u001b[32m    923\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mstd evaluated to zero after conversion to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, leading to division by zero.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_data = get_train_data()\n",
    "epochs = 20\n",
    "training_infos = []\n",
    "for model in models:\n",
    "    training_infos.append(train_model(model, device, train_data, epochs=epochs))\n",
    "show_training_infos(training_infos, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf7f98d-2f87-4a38-8bce-9bac7ffb69fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
